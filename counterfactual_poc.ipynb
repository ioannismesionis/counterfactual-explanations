{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual Explanations POC - House Prices\n",
    "\n",
    "This notebook demonstrates how to use DiCE-ML for generating counterfactual explanations in regression problems using the House Prices dataset. We'll show how to explain model predictions and suggest actionable changes to achieve desired house prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.imputation import ArbitraryNumberImputer, CategoricalImputer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "\n",
    "# Modelling\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Counterfactuals\n",
    "import dice_ml\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feature_engine\n",
    "\n",
    "feature_engine.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1460, 81)\n",
      "Test data shape: (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SalePrice'].describe([0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Scatter plot of SalePrice\n",
    "sns.scatterplot(data=train_df, x=train_df.index, y='SalePrice', ax=ax1)\n",
    "ax1.set_title('Sale Price Distribution')\n",
    "ax1.set_xlabel('House Index')\n",
    "ax1.set_ylabel('Sale Price ($)')\n",
    "\n",
    "# Density plot of SalePrice\n",
    "sns.kdeplot(data=train_df['SalePrice'], ax=ax2, fill=True)\n",
    "ax2.set_title('Sale Price Density Distribution')\n",
    "ax2.set_xlabel('Sale Price ($)')\n",
    "ax2.set_ylabel('Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and calculate percentages\n",
    "missing_values = train_df.isnull().sum()\n",
    "missing_percentages = (missing_values / len(train_df)) * 100\n",
    "missing_info = pd.DataFrame({\n",
    "    'Missing Values': missing_values[missing_values > 0],\n",
    "    'Percentage': missing_percentages[missing_values > 0]\n",
    "})\n",
    "missing_info.sort_values('Missing Values', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical features\n",
    "correlation_matrix = train_df.corr()\n",
    "\n",
    "# Create a figure with a larger size\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True,  # Show correlation values\n",
    "            cmap='coolwarm',  # Color scheme\n",
    "            center=0,  # Center the colormap at 0\n",
    "            fmt='.2f',  # Format correlation values to 2 decimal places\n",
    "            square=True,  # Make the plot square\n",
    "            linewidths=0.5)  # Add lines between cells\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print top correlations with SalePrice\n",
    "print(\"\\nTop 10 features most correlated with SalePrice:\")\n",
    "price_correlations = correlation_matrix['SalePrice'].sort_values(ascending=False)\n",
    "print(price_correlations[1:11])  # Skip first one as it's SalePrice itself\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable\n",
    "TARGET = 'SalePrice'\n",
    "\n",
    "# Separate features and target\n",
    "X = train_df.drop([TARGET, 'Id'], axis=1)\n",
    "y = train_df[TARGET]\n",
    "\n",
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {x_train.shape}\")\n",
    "print(f\"Test set shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NULL_COLS = [\n",
    "    \"PoolQC\",\n",
    "    \"MiscFeature\",\n",
    "    \"Alley\",\n",
    "    \"Fence\",\n",
    "]\n",
    "\n",
    "# 1. Drop columns with 80% missing values\n",
    "drop_missing_cols_obj = DropFeatures(features_to_drop=NULL_COLS)\n",
    "\n",
    "# Apply the transformation\n",
    "x_train = drop_missing_cols_obj.fit_transform(x_train)\n",
    "x_test = drop_missing_cols_obj.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify numerical and categorical columns\n",
    "# numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "# categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# print(f\"Number of numerical features: {len(numerical_cols)}\")\n",
    "# print(f\"Number of categorical features: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "num_imputer = ArbitraryNumberImputer(variables=numerical_cols, arbitrary_number=0)\n",
    "cat_imputer = CategoricalImputer(variables=categorical_cols, fill_value='missing')\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = OrdinalEncoder(variables=categorical_cols)\n",
    "\n",
    "# Apply transformations\n",
    "X_train_processed = num_imputer.fit_transform(X_train)\n",
    "X_train_processed = cat_imputer.fit_transform(X_train_processed)\n",
    "X_train_processed = encoder.fit_transform(X_train_processed)\n",
    "\n",
    "# Transform test set\n",
    "X_test_processed = num_imputer.transform(X_test)\n",
    "X_test_processed = cat_imputer.transform(X_test_processed)\n",
    "X_test_processed = encoder.transform(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using Recursive Feature Elimination with Cross-Validation (RFECV)\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Initialize base estimator for RFECV\n",
    "base_estimator = LassoCV(cv=5, random_state=42)\n",
    "\n",
    "# Create RFECV object\n",
    "rfecv = RFECV(\n",
    "    estimator=base_estimator,\n",
    "    step=1,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RFECV\n",
    "rfecv.fit(X_train_processed, y_train)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = X_train_processed.columns[rfecv.support_].tolist()\n",
    "print(f\"\\nNumber of selected features: {len(selected_features)}\")\n",
    "print(\"\\nSelected features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Plot number of features vs cross-validation score\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), -rfecv.grid_scores_)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Cross-Validation Score (MSE)')\n",
    "plt.title('Recursive Feature Elimination with Cross-Validation')\n",
    "plt.show()\n",
    "\n",
    "# Update processed datasets with selected features\n",
    "X_train_processed = X_train_processed[selected_features]\n",
    "X_test_processed = X_test_processed[selected_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM model\n",
    "model = lgb.LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "train_preds = model.predict(X_train_processed)\n",
    "test_preds = model.predict(X_test_processed)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Training Metrics:\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_train, train_preds)):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_train, train_preds):.2f}\")\n",
    "print(f\"R2: {r2_score(y_train, train_preds):.2f}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, test_preds)):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, test_preds):.2f}\")\n",
    "print(f\"R2: {r2_score(y_test, test_preds):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Counterfactual Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for DiCE\n",
    "dice_data = pd.concat([X_test_processed, pd.Series(test_preds, index=X_test_processed.index, name='predicted_price')], axis=1)\n",
    "\n",
    "# Create DiCE data object\n",
    "dice_data_obj = dice_ml.Data(\n",
    "    dataframe=dice_data,\n",
    "    continuous_features=X_test_processed.columns.tolist(),\n",
    "    outcome_name='predicted_price'\n",
    ")\n",
    "\n",
    "# Create DiCE model object\n",
    "dice_model = dice_ml.Model(model=model, backend=\"sklearn\", model_type=\"regressor\")\n",
    "\n",
    "# Create DiCE explainer\n",
    "dice_explainer = dice_ml.Dice(dice_data_obj, dice_model, method=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample house for counterfactual explanation\n",
    "sample_idx = 0  # You can change this to analyze different houses\n",
    "query_instance = X_test_processed.iloc[[sample_idx]]\n",
    "\n",
    "# Get current prediction\n",
    "current_price = model.predict(query_instance)[0]\n",
    "print(f\"Current predicted price: ${current_price:,.2f}\")\n",
    "\n",
    "# Generate counterfactuals\n",
    "cf_examples = dice_explainer.generate_counterfactuals(\n",
    "    query_instance,\n",
    "    total_CFs=3,\n",
    "    desired_range=(current_price * 1.1, current_price * 1.2),  # 10-20% higher price\n",
    "    features_to_vary=['GrLivArea', 'OverallQual', 'YearBuilt']  # Example features to vary\n",
    ")\n",
    "\n",
    "# Display counterfactuals\n",
    "cf_examples.visualize_as_dataframe(show_only_changes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
